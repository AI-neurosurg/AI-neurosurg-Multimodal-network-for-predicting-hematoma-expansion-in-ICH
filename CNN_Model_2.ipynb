{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9d931",
   "metadata": {
    "id": "98d9d931"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_1rJ5azcY94z",
   "metadata": {
    "id": "_1rJ5azcY94z"
   },
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d88d0",
   "metadata": {
    "id": "b92d88d0"
   },
   "source": [
    "## Function: Read images and a header (metadata) from a NIfTI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49863630",
   "metadata": {
    "id": "49863630"
   },
   "outputs": [],
   "source": [
    "def read_image_header(path):\n",
    "    load = nib.load(path)\n",
    "    image = load.get_fdata()\n",
    "    header = load.header\n",
    "    return image, header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f3137",
   "metadata": {
    "id": "4d3f3137"
   },
   "source": [
    "## Functions: Preprocessing for original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8438d6",
   "metadata": {
    "id": "dc8438d6"
   },
   "outputs": [],
   "source": [
    "# scale the CT density (Hounsfield Units) of the images after extracting brain and hematoma\n",
    "def density_scaling(image):\n",
    "    image[image < 0] = 0  # use the area with Hounsfield Units between 0 and 100,\n",
    "    image[image > 100] = 0  # which includes brain and hematoma\n",
    "    image = image / 100\n",
    "    return image\n",
    "\n",
    "# reslice and align the number of slices\n",
    "def reslice_and_align_slice(image, header, new_spacing=2, new_slices=80):\n",
    "    # reslice - set new spacing (new_spacing), with which reslice the images\n",
    "    z_axis_spacing = header['pixdim'][3].round(2)  # get the image spacing from the header\n",
    "    spacing_factor = z_axis_spacing / new_spacing\n",
    "    image = ndimage.zoom(image, (1, 1, spacing_factor))\n",
    "\n",
    "    # align the number of slices - set the new number of slices (new_slices)\n",
    "    slices = header['dim'][3]  # get the number of slices from the header\n",
    "    slices_resliced = slices * spacing_factor  # culculate the number of slices after reslicing\n",
    "    slices_resliced_ = int(slices_resliced.round(0))\n",
    "    if slices_resliced_ > new_slices:  # eliminate redundant slices without brain to match the new number of slices\n",
    "        num_reduce = slices_resliced_ - new_slices\n",
    "        image = np.delete(image, np.s_[:num_reduce], 2)\n",
    "        return image\n",
    "    elif slices_resliced_ < new_slices:  # add slices with values of zero to match the new number of slices\n",
    "        num_add = new_slices - slices_resliced_\n",
    "        ndarray_zero = np.zeros((image.shape[0], image.shape[1], num_add))\n",
    "        image = np.concatenate([ndarray_zero, image], 2)\n",
    "        return image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "# unify the pixel size\n",
    "def unify(image, header):\n",
    "    # calculate the magnification for resizing the images assuming the new pixel size is 0.5 x 0.5\n",
    "    x_pixel = header['pixdim'][1]  # Since the pixel is square, only the x-axis of the pixel is calculated.\n",
    "    magnification = x_pixel / 0.5\n",
    "    # unify\n",
    "    image = ndimage.zoom(image, (magnification, magnification, 1))\n",
    "    # padding to restore the image shape to '512 x 512 x 80' after the unification\n",
    "    padding_0 = int((513 - image.shape[0]) / 2)\n",
    "    padding_1 = int((513 - image.shape[1]) / 2)\n",
    "    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # anterior of the brain\n",
    "    image = np.concatenate([ndarray_zero, image], 0)\n",
    "    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # posterior of the brain\n",
    "    image = np.concatenate([image, ndarray_zero], 0)\n",
    "    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # right of the brain\n",
    "    image = np.concatenate([ndarray_zero, image], 1)\n",
    "    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # left of the brain\n",
    "    image = np.concatenate([image, ndarray_zero], 1)\n",
    "    image[image < 0] = 0  # During the unification process, some pixel values may become\n",
    "    image[image > 1] = 1  # slightly lower than 0 or higher than 1, so the excess are aligned to 0 or 1.\n",
    "    return image\n",
    "\n",
    "# resize the images\n",
    "def resize(image,\n",
    "           image_size=256  # the image size to be created\n",
    "           ):\n",
    "    # resize the image size '512 x 512' to the size specified by the parameter\n",
    "    image = ndimage.zoom(image, (image_size/512, image_size/512, 1))\n",
    "    image[image < 0] = 0  # During the resizing process, some pixel values may become\n",
    "    image[image > 1] = 1  # slightly lower than 0 or higher than 1, so the excess are aligned to 0 or 1.\n",
    "    return image\n",
    "\n",
    "# get processed images using above defined functions\n",
    "def get_processed_images(path):\n",
    "    image, header = read_image_header(path)\n",
    "    image = density_scaling(image)\n",
    "    image = reslice_and_align_slice(image, header)\n",
    "    image = unify(image, header)\n",
    "    image = resize(image)\n",
    "    # rotate the images by 90 degrees\n",
    "    image = ndimage.rotate(image, 90, reshape=False)\n",
    "    return image.round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d46a2",
   "metadata": {
    "id": "509d46a2"
   },
   "source": [
    "## Functions: Preprocessing for masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd0f99",
   "metadata": {
    "id": "18cd0f99"
   },
   "outputs": [],
   "source": [
    "# reslice and align the number of slices\n",
    "def reslice_and_align_slice_mask(image, header, new_spacing=2, new_slices=80):\n",
    "    # reslice - set new spacing (new_spacing), with which reslice the images\n",
    "    z_axis_spacing = header['pixdim'][3].round(2)  # get the image spacing from the header\n",
    "    spacing_factor = z_axis_spacing / new_spacing\n",
    "    image = ndimage.zoom(image, (1, 1, spacing_factor))\n",
    "    image[image < 0.2] = 0\n",
    "    image[image >= 0.2] = 1\n",
    "\n",
    "    # align the number of slices - set the new number of slices (new_slices)\n",
    "    slices = header['dim'][3]  # get the number of slices from the header\n",
    "    slices_resliced = slices * spacing_factor  # culculate the number of slices after reslicing\n",
    "    slices_resliced_ = int(slices_resliced.round(0))\n",
    "    if slices_resliced_ > new_slices:  # eliminate redundant slices without brain to match the new number of slices\n",
    "        num_reduce = slices_resliced_ - new_slices\n",
    "        image = np.delete(image, np.s_[:num_reduce], 2)\n",
    "        return image\n",
    "    elif slices_resliced_ < new_slices:  # add slices with values of zero to match the new number of slices\n",
    "        num_add = new_slices - slices_resliced_\n",
    "        ndarray_zero = np.zeros((image.shape[0], image.shape[1], num_add))\n",
    "        image = np.concatenate([ndarray_zero, image], 2)\n",
    "        return image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "# unify the pixel size\n",
    "def unify_mask(image, header):\n",
    "    # calculate the magnification for resizing the images assuming the new pixel size is 0.5 x 0.5\n",
    "    x_pixel = header['pixdim'][1]  # Since the pixel is square, only the x-axis of the pixel is calculated.\n",
    "    magnification = x_pixel / 0.5\n",
    "    # unify\n",
    "    image = ndimage.zoom(image, (magnification, magnification, 1))\n",
    "    # padding to restore the image shape to '512 x 512 x 80' after the unification\n",
    "    padding_0 = int((513 - image.shape[0]) / 2)\n",
    "    padding_1 = int((513 - image.shape[1]) / 2)\n",
    "    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # anterior of the brain\n",
    "    image = np.concatenate([ndarray_zero, image], 0)\n",
    "    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # posterior of the brain\n",
    "    image = np.concatenate([image, ndarray_zero], 0)\n",
    "    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # right of the brain\n",
    "    image = np.concatenate([ndarray_zero, image], 1)\n",
    "    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # left of the brain\n",
    "    image = np.concatenate([image, ndarray_zero], 1)\n",
    "    image[image < 0.2] = 0   # after the unification, the values of the images are no longer binary,\n",
    "    image[image >= 0.2] = 1  # therefore, binarize with a threshold of 0.2\n",
    "    return image\n",
    "\n",
    "# resize the images\n",
    "def resize_mask(image,\n",
    "                image_size=256  # the image size to be created\n",
    "               ):\n",
    "    # resize the image size '512 x 512' to the size specified by the parameter\n",
    "    image = ndimage.zoom(image, (image_size/512, image_size/512, 1))\n",
    "    image[image < 0.2] = 0   # after resizing, the values of the images are no longer binary,\n",
    "    image[image >= 0.2] = 1  # therefore, binarize with a threshold of 0.2\n",
    "    return image\n",
    "\n",
    "# get processed images using above defined functions\n",
    "def get_processed_images_mask(path):\n",
    "    image, header = read_image_header(path)\n",
    "    image = reslice_and_align_slice_mask(image, header)\n",
    "    image = unify_mask(image, header)\n",
    "    image = resize_mask(image)\n",
    "    # rotate the images by 90 degrees\n",
    "    image = ndimage.rotate(image, 90, reshape=False)\n",
    "    return image.round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f942a",
   "metadata": {
    "id": "5b0f942a"
   },
   "source": [
    "## Function: Extract hematoma only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65477d86",
   "metadata": {
    "id": "65477d86"
   },
   "outputs": [],
   "source": [
    "def extract_hematoma(path, path_mask):\n",
    "    list = [os.path.join(path, i) for i in sorted(os.listdir(path))]\n",
    "    original = np.array([get_processed_images(j) for j in tqdm(list)])\n",
    "    original = original.astype('float32')\n",
    "    list_mask = [os.path.join(path_mask, i) for i in sorted(os.listdir(path_mask))]\n",
    "    mask = np.array([get_processed_images_mask(j) for j in tqdm(list_mask)])\n",
    "    mask = mask.astype('float32')\n",
    "    hematoma = original - 1 + mask\n",
    "    hematoma[hematoma <= 0] = 0\n",
    "    return hematoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YA-pOgLW8oBd",
   "metadata": {
    "id": "YA-pOgLW8oBd"
   },
   "source": [
    "## Specify the paths where NIfTI files are stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TAOf3RIB0ifH",
   "metadata": {
    "id": "TAOf3RIB0ifH"
   },
   "source": [
    "The NIfTI files should be stored in each directory according to the following classification method.\n",
    "*   training and validation, expansion, original CT images\n",
    "*   training and validation, expansion, masked images\n",
    "*   training and validation, no expansion, original CT images\n",
    "*   training and validation, no expansion, masked images\n",
    "*   test, expansion, original CT images\n",
    "*   test, expansion, masked images\n",
    "*   test, no expansion, original CT images\n",
    "*   test, no expansion, masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c94ec5",
   "metadata": {
    "id": "b8c94ec5"
   },
   "outputs": [],
   "source": [
    "path_expansion_train_val = \"PATH\"\n",
    "path_expansion_train_val_mask = \"PATH\"\n",
    "path_no_expansion_train_val = \"PATH\"\n",
    "path_no_expansion_train_val_mask = \"PATH\"\n",
    "path_expansion_test = \"PATH\"\n",
    "path_expansion_test_mask = \"PATH\"\n",
    "path_no_expansion_test = \"PATH\"\n",
    "path_no_expansion_test_mask = \"PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zAWvfNGK-q9l",
   "metadata": {
    "id": "zAWvfNGK-q9l"
   },
   "source": [
    "## Create data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2be9c",
   "metadata": {
    "id": "2eb2be9c"
   },
   "outputs": [],
   "source": [
    "list_expansion_train_val = [os.path.join(path_expansion_train_val, i) for i in sorted(os.listdir(path_expansion_train_val))]\n",
    "expansion_train_val = np.array([get_processed_images(j) for j in tqdm(list_expansion_train_val)])\n",
    "list_no_expansion_train_val = [os.path.join(path_no_expansion_train_val, i) for i in sorted(os.listdir(path_no_expansion_train_val))]\n",
    "no_expansion_train_val = np.array([get_processed_images(j) for j in tqdm(list_no_expansion_train_val)])\n",
    "list_expansion_test = [os.path.join(path_expansion_test, i) for i in sorted(os.listdir(path_expansion_test))]\n",
    "expansion_test = np.array([get_processed_images(j) for j in tqdm(list_expansion_test)])\n",
    "list_no_expansion_test = [os.path.join(path_no_expansion_test, i) for i in sorted(os.listdir(path_no_expansion_test))]\n",
    "no_expansion_test = np.array([get_processed_images(j) for j in tqdm(list_no_expansion_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eUit-siP-yjI",
   "metadata": {
    "id": "eUit-siP-yjI"
   },
   "source": [
    "## Convert array type to float32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b31ef",
   "metadata": {
    "id": "c06b31ef"
   },
   "outputs": [],
   "source": [
    "expansion_train_val = expansion_train_val.astype('float32')\n",
    "no_expansion_train_val = no_expansion_train_val.astype('float32')\n",
    "expansion_test = expansion_test.astype('float32')\n",
    "no_expansion_test = no_expansion_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kDevG9bQWNIr",
   "metadata": {
    "id": "kDevG9bQWNIr"
   },
   "source": [
    "## Shuffle the data in the arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba1ee1",
   "metadata": {
    "id": "81ba1ee1"
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.shuffle(expansion_train_val)\n",
    "np.random.shuffle(no_expansion_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lJ-PeYFzWRu8",
   "metadata": {
    "id": "lJ-PeYFzWRu8"
   },
   "source": [
    "## 70% were assigned to the training set and the rest to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab8e10",
   "metadata": {
    "id": "a8ab8e10"
   },
   "outputs": [],
   "source": [
    "expansion_train = expansion_train_val[:int(len(expansion_train_val)*0.7)]\n",
    "expansion_val = expansion_train_val[int(len(expansion_train_val)*0.7):]\n",
    "no_expansion_train = no_expansion_train_val[:int(len(no_expansion_train_val)*0.7)]\n",
    "no_expansion_val = no_expansion_train_val[int(len(no_expansion_train_val)*0.7):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guzuu56iWYSh",
   "metadata": {
    "id": "guzuu56iWYSh"
   },
   "source": [
    "## Data augmentation by rotating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3U7HFytfKwW",
   "metadata": {
    "id": "-3U7HFytfKwW"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "angles = [30]\n",
    "for j in range(len(angles)):\n",
    "    for i in tqdm(range(len(expansion_train))):\n",
    "        rotation = ndimage.rotate(expansion_train[i], angles[j], reshape=False)\n",
    "        rotation[rotation < 0] = 0\n",
    "        rotation[rotation > 1] = 1\n",
    "        rotation = np.expand_dims(rotation, axis=0)\n",
    "        expansion_train = np.concatenate((expansion_train, rotation), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imfeVJrHWcgG",
   "metadata": {
    "id": "imfeVJrHWcgG"
   },
   "source": [
    "## Data augmentation by flipping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yzAAkbNNdYD-",
   "metadata": {
    "id": "yzAAkbNNdYD-"
   },
   "outputs": [],
   "source": [
    "expansion_train = np.concatenate((expansion_train, np.flip(expansion_train, 2)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IJ3yM7YBWhwE",
   "metadata": {
    "id": "IJ3yM7YBWhwE"
   },
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f3bcf",
   "metadata": {
    "id": "ae1f3bcf"
   },
   "outputs": [],
   "source": [
    "label_expansion_train = np.array([1 for i in range(len(expansion_train))])\n",
    "label_expansion_val = np.array([1 for i in range(len(expansion_val))])\n",
    "label_no_expansion_train = np.array([0 for i in range(len(no_expansion_train))])\n",
    "label_no_expansion_val = np.array([0 for i in range(len(no_expansion_val))])\n",
    "label_expansion_test = np.array([1 for i in range(len(expansion_test))])\n",
    "label_no_expansion_test = np.array([0 for i in range(len(no_expansion_test))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1hqa-_uwWqCM",
   "metadata": {
    "id": "1hqa-_uwWqCM"
   },
   "source": [
    "## Concatenate expansion and no expansion arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e3f8a",
   "metadata": {
    "id": "0c7e3f8a"
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate((expansion_train, no_expansion_train), axis=0)\n",
    "x_val = np.concatenate((expansion_val, no_expansion_val), axis=0)\n",
    "y_train = np.concatenate((label_expansion_train, label_no_expansion_train), axis=0)\n",
    "y_val = np.concatenate((label_expansion_val, label_no_expansion_val), axis=0)\n",
    "x_test = np.concatenate((expansion_test, no_expansion_test), axis=0)\n",
    "y_test = np.concatenate((label_expansion_test, label_no_expansion_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TJaIxRsLWwrz",
   "metadata": {
    "id": "TJaIxRsLWwrz"
   },
   "source": [
    "## Add a dimension to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd6294",
   "metadata": {
    "id": "bbfd6294"
   },
   "outputs": [],
   "source": [
    "x_train = tf.expand_dims(x_train, axis=4)\n",
    "x_val = tf.expand_dims(x_val, axis=4)\n",
    "x_test = tf.expand_dims(x_test, axis=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jyNl3a1rZNje",
   "metadata": {
    "id": "jyNl3a1rZNje"
   },
   "source": [
    "#  **Training and validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-hT4OZ20-QNr",
   "metadata": {
    "id": "-hT4OZ20-QNr"
   },
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff311fb",
   "metadata": {
    "id": "cff311fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_image(height=expansion_train.shape[1], width=expansion_train.shape[2], number_of_slices=expansion_train.shape[3]):\n",
    "\n",
    "    inputs = keras.Input((height, width, number_of_slices, 1))\n",
    "\n",
    "    l = layers.Conv3D(filters=64, kernel_size=(19,19,7), kernel_initializer=\"he_normal\")(inputs)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation(\"relu\")(l)\n",
    "    l = layers.MaxPool3D(pool_size=2)(l)\n",
    "\n",
    "    l = layers.Conv3D(filters=64, kernel_size=(19,19,7), kernel_initializer=\"he_normal\")(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation(\"relu\")(l)\n",
    "    l = layers.MaxPool3D(pool_size=2)(l)\n",
    "\n",
    "    l = layers.Conv3D(filters=128, kernel_size=(14,14,5), kernel_initializer=\"he_normal\")(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation(\"relu\")(l)\n",
    "    l = layers.MaxPool3D(pool_size=2)(l)\n",
    "\n",
    "    l = layers.Conv3D(filters=256, kernel_size=(11,11,4), kernel_initializer=\"he_normal\")(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation(\"relu\")(l)\n",
    "    l = layers.MaxPool3D(pool_size=2)(l)\n",
    "\n",
    "    l = layers.GlobalAveragePooling3D()(l)\n",
    "    l = layers.Dense(units=512, activation=\"relu\", kernel_initializer=\"he_normal\")(l)\n",
    "    l = layers.Dropout(0.3)(l)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(l)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"3DCNN\")\n",
    "    return model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = model_image()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iJX1C9Lw_ATg",
   "metadata": {
    "id": "iJX1C9Lw_ATg"
   },
   "source": [
    "## Compile and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9f847",
   "metadata": {
    "id": "27d9f847"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"AUC\", tf.keras.metrics.Recall()])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=os.path.join('PATH', '{epoch:03d}.h5'))\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=2, epochs=70, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2BrweGsZab2",
   "metadata": {
    "id": "f2BrweGsZab2"
   },
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rJSVaopXA9cK",
   "metadata": {
    "id": "rJSVaopXA9cK"
   },
   "source": [
    "## Specify the path to the HFD5 file that had better sensitivity and AUC in the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f574fc",
   "metadata": {
    "id": "a1f574fc"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g9s2lkrdD9Ep",
   "metadata": {
    "id": "g9s2lkrdD9Ep"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L9T8bGSohdDk",
   "metadata": {
    "id": "L9T8bGSohdDk"
   },
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test, batch_size=2, verbose=1)\n",
    "y_prediction[y_prediction < 0.5] = 0\n",
    "y_prediction[y_prediction >= 0.5] = 1\n",
    "y_prediction = y_prediction.astype(\"int64\")\n",
    "result = confusion_matrix(y_test, y_prediction)\n",
    "sensitivity = recall_score(y_test, y_prediction)\n",
    "specificity = recall_score(y_test, y_prediction, pos_label=0)\n",
    "accuracy = accuracy_score(y_test, y_prediction)\n",
    "auc = roc_auc_score(y_test, y_prediction)\n",
    "print(result)\n",
    "print(\"sensitivity: {:.3f}\".format(sensitivity))\n",
    "print(\"specificity: {:.3f}\".format(specificity))\n",
    "print(\"accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"AUC: {:.3f}\".format(auc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuClass": "premium",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
