{"cells":[{"cell_type":"code","execution_count":null,"id":"98d9d931","metadata":{"id":"98d9d931"},"outputs":[],"source":["import nibabel as nib\n","import numpy as np\n","from scipy import ndimage\n","from tqdm import tqdm\n","import os\n","import random\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, roc_auc_score"]},{"cell_type":"markdown","source":["# **Preprocessing**"],"metadata":{"id":"_1rJ5azcY94z"},"id":"_1rJ5azcY94z"},{"cell_type":"markdown","metadata":{"id":"b92d88d0"},"source":["## Function: Read images and a header (metadata) from a NIfTI file"],"id":"b92d88d0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"49863630"},"outputs":[],"source":["def read_image_header(path):\n","    load = nib.load(path)\n","    image = load.get_fdata()\n","    header = load.header\n","    return image, header"],"id":"49863630"},{"cell_type":"markdown","metadata":{"id":"4d3f3137"},"source":["## Functions: Preprocessing for original images"],"id":"4d3f3137"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc8438d6"},"outputs":[],"source":["# normalize the images after extracting brain and hematoma\n","def normalize(image):\n","    image[image < 0] = 0  # use the area with Hounsfield Units between 0 and 100,\n","    image[image > 100] = 0  # which includes brain and hematoma\n","    image = image / 100\n","    return image\n","\n","# reslice and align the number of slices\n","def reslice_and_align_slice(image, header, new_spacing=2, new_slices=80):\n","    # reslice - set new spacing (new_spacing), with which reslice the images\n","    z_axis_spacing = header['pixdim'][3].round(2)  # get the image spacing from the header\n","    spacing_factor = z_axis_spacing / new_spacing\n","    image = ndimage.zoom(image, (1, 1, spacing_factor))\n","\n","    # align the number of slices - set the new number of slices (new_slices)\n","    slices = header['dim'][3]  # get the number of slices from the header\n","    slices_resliced = slices * spacing_factor  # culculate the number of slices after reslicing\n","    slices_resliced_ = int(slices_resliced.round(0))\n","    if slices_resliced_ > new_slices:  # eliminate redundant slices without brain to match the new number of slices\n","        num_reduce = slices_resliced_ - new_slices\n","        image = np.delete(image, np.s_[:num_reduce], 2)\n","        return image\n","    elif slices_resliced_ < new_slices:  # add slices with values of zero to match the new number of slices\n","        num_add = new_slices - slices_resliced_\n","        ndarray_zero = np.zeros((image.shape[0], image.shape[1], num_add))\n","        image = np.concatenate([ndarray_zero, image], 2)\n","        return image\n","    else:\n","        return image\n","\n","# unify the pixel size\n","def unify(image, header):\n","    # calculate the magnification for resizing the images assuming the new pixel size is 0.5 x 0.5\n","    x_pixel = header['pixdim'][1]  # Since the pixel is square, only the x-axis of the pixel is calculated.\n","    magnification = x_pixel / 0.5\n","    # unify\n","    image = ndimage.zoom(image, (magnification, magnification, 1))\n","    # padding to restore the image shape to '512 x 512 x 80' after the unification\n","    padding_0 = int((513 - image.shape[0]) / 2)\n","    padding_1 = int((513 - image.shape[1]) / 2)\n","    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # anterior of the brain\n","    image = np.concatenate([ndarray_zero, image], 0)\n","    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # posterior of the brain\n","    image = np.concatenate([image, ndarray_zero], 0)\n","    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # right of the brain\n","    image = np.concatenate([ndarray_zero, image], 1)\n","    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # left of the brain\n","    image = np.concatenate([image, ndarray_zero], 1)\n","    image[image < 0] = 0  # During the unification process, some pixel values may become\n","    image[image > 1] = 1  # slightly lower than 0 or higher than 1, so the excess are aligned to 0 or 1.\n","    return image\n","\n","# resize the images\n","def resize(image,\n","           image_size=256  # the image size to be created\n","           ):\n","    # resize the image size '512 x 512' to the size specified by the parameter\n","    image = ndimage.zoom(image, (image_size/512, image_size/512, 1))\n","    image[image < 0] = 0  # During the resizing process, some pixel values may become\n","    image[image > 1] = 1  # slightly lower than 0 or higher than 1, so the excess are aligned to 0 or 1.\n","    return image\n","\n","# get processed images using above defined functions\n","def get_processed_images(path):\n","    image, header = read_image_header(path)\n","    image = normalize(image)\n","    image = reslice_and_align_slice(image, header)\n","    image = unify(image, header)\n","    image = resize(image)\n","    # rotate the images by 90 degrees\n","    image = ndimage.rotate(image, 90, reshape=False)\n","    return image.round(10)"],"id":"dc8438d6"},{"cell_type":"markdown","metadata":{"id":"509d46a2"},"source":["## Functions: Preprocessing for masked images"],"id":"509d46a2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"18cd0f99"},"outputs":[],"source":["# reslice and align the number of slices\n","def reslice_and_align_slice_mask(image, header, new_spacing=2, new_slices=80):\n","    # reslice - set new spacing (new_spacing), with which reslice the images\n","    z_axis_spacing = header['pixdim'][3].round(2)  # get the image spacing from the header\n","    spacing_factor = z_axis_spacing / new_spacing\n","    image = ndimage.zoom(image, (1, 1, spacing_factor))\n","    image[image < 0.2] = 0\n","    image[image >= 0.2] = 1\n","\n","    # align the number of slices - set the new number of slices (new_slices)\n","    slices = header['dim'][3]  # get the number of slices from the header\n","    slices_resliced = slices * spacing_factor  # culculate the number of slices after reslicing\n","    slices_resliced_ = int(slices_resliced.round(0))\n","    if slices_resliced_ > new_slices:  # eliminate redundant slices without brain to match the new number of slices\n","        num_reduce = slices_resliced_ - new_slices\n","        image = np.delete(image, np.s_[:num_reduce], 2)\n","        return image\n","    elif slices_resliced_ < new_slices:  # add slices with values of zero to match the new number of slices\n","        num_add = new_slices - slices_resliced_\n","        ndarray_zero = np.zeros((image.shape[0], image.shape[1], num_add))\n","        image = np.concatenate([ndarray_zero, image], 2)\n","        return image\n","    else:\n","        return image\n","\n","# unify the pixel size\n","def unify_mask(image, header):\n","    # calculate the magnification for resizing the images assuming the new pixel size is 0.5 x 0.5\n","    x_pixel = header['pixdim'][1]  # Since the pixel is square, only the x-axis of the pixel is calculated.\n","    magnification = x_pixel / 0.5\n","    # unify\n","    image = ndimage.zoom(image, (magnification, magnification, 1))\n","    # padding to restore the image shape to '512 x 512 x 80' after the unification\n","    padding_0 = int((513 - image.shape[0]) / 2)\n","    padding_1 = int((513 - image.shape[1]) / 2)\n","    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # anterior of the brain\n","    image = np.concatenate([ndarray_zero, image], 0)\n","    ndarray_zero = np.zeros((padding_0, image.shape[1], image.shape[2]))  # posterior of the brain\n","    image = np.concatenate([image, ndarray_zero], 0)\n","    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # right of the brain\n","    image = np.concatenate([ndarray_zero, image], 1)\n","    ndarray_zero = np.zeros((image.shape[0], padding_1, image.shape[2]))  # left of the brain\n","    image = np.concatenate([image, ndarray_zero], 1)\n","    image[image < 0.2] = 0   # after the unification, the values of the images are no longer binary,\n","    image[image >= 0.2] = 1  # therefore, binarize with a threshold of 0.2\n","    return image\n","\n","# resize the images\n","def resize_mask(image,\n","                image_size=256  # the image size to be created\n","               ):\n","    # resize the image size '512 x 512' to the size specified by the parameter\n","    image = ndimage.zoom(image, (image_size/512, image_size/512, 1))\n","    image[image < 0.2] = 0   # after resizing, the values of the images are no longer binary,\n","    image[image >= 0.2] = 1  # therefore, binarize with a threshold of 0.2\n","    return image\n","\n","# get processed images using above defined functions\n","def get_processed_images_mask(path):\n","    image, header = read_image_header(path)\n","    image = reslice_and_align_slice_mask(image, header)\n","    image = unify_mask(image, header)\n","    image = resize_mask(image)\n","    # rotate the images by 90 degrees\n","    image = ndimage.rotate(image, 90, reshape=False)\n","    return image.round(10)"],"id":"18cd0f99"},{"cell_type":"markdown","metadata":{"id":"5b0f942a"},"source":["## Function: Extract hematoma only"],"id":"5b0f942a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"65477d86"},"outputs":[],"source":["def extract_hematoma(path, path_mask):\n","    list = [os.path.join(path, i) for i in sorted(os.listdir(path))]\n","    original = np.array([get_processed_images(j) for j in tqdm(list)])\n","    original = original.astype('float32')\n","    list_mask = [os.path.join(path_mask, i) for i in sorted(os.listdir(path_mask))]\n","    mask = np.array([get_processed_images_mask(j) for j in tqdm(list_mask)])\n","    mask = mask.astype('float32')\n","    hematoma = original - 1 + mask\n","    hematoma[hematoma <= 0] = 0\n","    return hematoma"],"id":"65477d86"},{"cell_type":"markdown","source":["## Specify the paths where NIfTI files are stored"],"metadata":{"id":"YA-pOgLW8oBd"},"id":"YA-pOgLW8oBd"},{"cell_type":"markdown","source":["The NIfTI files should be stored in each directory according to the following classification method.\n","*   training and validation, expansion, original CT images\n","*   training and validation, expansion, masked images\n","*   training and validation, no expansion, original CT images\n","*   training and validation, no expansion, masked images\n","*   test, expansion, original CT images\n","*   test, expansion, masked images\n","*   test, no expansion, original CT images\n","*   test, no expansion, masked images"],"metadata":{"id":"TAOf3RIB0ifH"},"id":"TAOf3RIB0ifH"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8c94ec5"},"outputs":[],"source":["path_expansion_train_val = \"PATH\"\n","path_expansion_train_val_mask = \"PATH\"\n","path_no_expansion_train_val = \"PATH\"\n","path_no_expansion_train_val_mask = \"PATH\"\n","path_expansion_test = \"PATH\"\n","path_expansion_test_mask = \"PATH\"\n","path_no_expansion_test = \"PATH\"\n","path_no_expansion_test_mask = \"PATH\""],"id":"b8c94ec5"},{"cell_type":"markdown","source":["## Create data arrays"],"metadata":{"id":"zAWvfNGK-q9l"},"id":"zAWvfNGK-q9l"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eb2be9c"},"outputs":[],"source":["list_expansion_train_val = [os.path.join(path_expansion_train_val, i) for i in sorted(os.listdir(path_expansion_train_val))]\n","expansion_train_val = np.array([get_processed_images(j) for j in tqdm(list_expansion_train_val)])\n","list_no_expansion_train_val = [os.path.join(path_no_expansion_train_val, i) for i in sorted(os.listdir(path_no_expansion_train_val))]\n","no_expansion_train_val = np.array([get_processed_images(j) for j in tqdm(list_no_expansion_train_val)])\n","list_expansion_test = [os.path.join(path_expansion_test, i) for i in sorted(os.listdir(path_expansion_test))]\n","expansion_test = np.array([get_processed_images(j) for j in tqdm(list_expansion_test)])\n","list_no_expansion_test = [os.path.join(path_no_expansion_test, i) for i in sorted(os.listdir(path_no_expansion_test))]\n","no_expansion_test = np.array([get_processed_images(j) for j in tqdm(list_no_expansion_test)])"],"id":"2eb2be9c"},{"cell_type":"markdown","source":["## Convert array type to float32\n","\n"],"metadata":{"id":"eUit-siP-yjI"},"id":"eUit-siP-yjI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c06b31ef"},"outputs":[],"source":["expansion_train_val = expansion_train_val.astype('float32')\n","no_expansion_train_val = no_expansion_train_val.astype('float32')\n","expansion_test = expansion_test.astype('float32')\n","no_expansion_test = no_expansion_test.astype('float32')"],"id":"c06b31ef"},{"cell_type":"markdown","source":["## Shuffle the data in the arrays\n","\n"],"metadata":{"id":"kDevG9bQWNIr"},"id":"kDevG9bQWNIr"},{"cell_type":"code","execution_count":null,"id":"81ba1ee1","metadata":{"id":"81ba1ee1"},"outputs":[],"source":["random.seed(0)\n","np.random.shuffle(expansion_train_val)\n","np.random.shuffle(no_expansion_train_val)"]},{"cell_type":"markdown","source":["## 70% were assigned to the training set and the rest to the validation set"],"metadata":{"id":"lJ-PeYFzWRu8"},"id":"lJ-PeYFzWRu8"},{"cell_type":"code","execution_count":null,"id":"a8ab8e10","metadata":{"id":"a8ab8e10"},"outputs":[],"source":["expansion_train = expansion_train_val[:int(len(expansion_train_val)*0.7)]\n","expansion_val = expansion_train_val[int(len(expansion_train_val)*0.7):]\n","no_expansion_train = no_expansion_train_val[:int(len(no_expansion_train_val)*0.7)]\n","no_expansion_val = no_expansion_train_val[int(len(no_expansion_train_val)*0.7):]"]},{"cell_type":"markdown","source":["## Data augmentation by rotating images"],"metadata":{"id":"guzuu56iWYSh"},"id":"guzuu56iWYSh"},{"cell_type":"code","source":["from tqdm import tqdm\n","from scipy import ndimage\n","angles = [30]\n","for j in range(len(angles)):\n","    for i in tqdm(range(len(expansion_train))):\n","        rotation = ndimage.rotate(expansion_train[i], angles[j], reshape=False)\n","        rotation[rotation < 0] = 0\n","        rotation[rotation > 1] = 1\n","        rotation = np.expand_dims(rotation, axis=0)\n","        expansion_train = np.concatenate((expansion_train, rotation), axis=0)"],"metadata":{"id":"-3U7HFytfKwW"},"id":"-3U7HFytfKwW","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data augmentation by flipping images"],"metadata":{"id":"imfeVJrHWcgG"},"id":"imfeVJrHWcgG"},{"cell_type":"code","source":["expansion_train = np.concatenate((expansion_train, np.flip(expansion_train, 2)), axis=0)"],"metadata":{"id":"yzAAkbNNdYD-"},"id":"yzAAkbNNdYD-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Labeling"],"metadata":{"id":"IJ3yM7YBWhwE"},"id":"IJ3yM7YBWhwE"},{"cell_type":"code","execution_count":null,"id":"ae1f3bcf","metadata":{"id":"ae1f3bcf"},"outputs":[],"source":["label_expansion_train = np.array([1 for i in range(len(expansion_train))])\n","label_expansion_val = np.array([1 for i in range(len(expansion_val))])\n","label_no_expansion_train = np.array([0 for i in range(len(no_expansion_train))])\n","label_no_expansion_val = np.array([0 for i in range(len(no_expansion_val))])\n","label_expansion_test = np.array([1 for i in range(len(expansion_test))])\n","label_no_expansion_test = np.array([0 for i in range(len(no_expansion_test))])"]},{"cell_type":"markdown","source":["## Concatenate expansion and no expansion arrays"],"metadata":{"id":"1hqa-_uwWqCM"},"id":"1hqa-_uwWqCM"},{"cell_type":"code","execution_count":null,"id":"0c7e3f8a","metadata":{"id":"0c7e3f8a"},"outputs":[],"source":["x_train = np.concatenate((expansion_train, no_expansion_train), axis=0)\n","x_val = np.concatenate((expansion_val, no_expansion_val), axis=0)\n","y_train = np.concatenate((label_expansion_train, label_no_expansion_train), axis=0)\n","y_val = np.concatenate((label_expansion_val, label_no_expansion_val), axis=0)\n","x_test = np.concatenate((expansion_test, no_expansion_test), axis=0)\n","y_test = np.concatenate((label_expansion_test, label_no_expansion_test), axis=0)"]},{"cell_type":"markdown","source":["## Add a dimension to arrays"],"metadata":{"id":"TJaIxRsLWwrz"},"id":"TJaIxRsLWwrz"},{"cell_type":"code","execution_count":null,"id":"bbfd6294","metadata":{"id":"bbfd6294"},"outputs":[],"source":["x_train = tf.expand_dims(x_train, axis=4)\n","x_val = tf.expand_dims(x_val, axis=4)\n","x_test = tf.expand_dims(x_test, axis=4)"]},{"cell_type":"markdown","source":["#  **Training and validation**"],"metadata":{"id":"jyNl3a1rZNje"},"id":"jyNl3a1rZNje"},{"cell_type":"markdown","source":["## Model architecture"],"metadata":{"id":"-hT4OZ20-QNr"},"id":"-hT4OZ20-QNr"},{"cell_type":"code","execution_count":null,"id":"cff311fb","metadata":{"scrolled":true,"id":"cff311fb"},"outputs":[],"source":["def model_image(height=expansion_train.shape[1], width=expansion_train.shape[2], number_of_slices=expansion_train.shape[3]):\n","\n","    inputs = keras.Input((height, width, number_of_slices, 1))\n","\n","    l = layers.Conv3D(filters=64, kernel_size=(19,19,7), kernel_initializer=\"he_normal\")(inputs)\n","    l = layers.BatchNormalization()(l)\n","    l = layers.Activation(\"relu\")(l)\n","    l = layers.MaxPool3D(pool_size=2)(l)\n","\n","    l = layers.Conv3D(filters=64, kernel_size=(19,19,7), kernel_initializer=\"he_normal\")(l)\n","    l = layers.BatchNormalization()(l)\n","    l = layers.Activation(\"relu\")(l)\n","    l = layers.MaxPool3D(pool_size=2)(l)\n","\n","    l = layers.Conv3D(filters=128, kernel_size=(14,14,5), kernel_initializer=\"he_normal\")(l)\n","    l = layers.BatchNormalization()(l)\n","    l = layers.Activation(\"relu\")(l)\n","    l = layers.MaxPool3D(pool_size=2)(l)\n","\n","    l = layers.Conv3D(filters=256, kernel_size=(11,11,4), kernel_initializer=\"he_normal\")(l)\n","    l = layers.BatchNormalization()(l)\n","    l = layers.Activation(\"relu\")(l)\n","    l = layers.MaxPool3D(pool_size=2)(l)\n","\n","    l = layers.GlobalAveragePooling3D()(l)\n","    l = layers.Dense(units=512, activation=\"relu\", kernel_initializer=\"he_normal\")(l)\n","    l = layers.Dropout(0.3)(l)\n","\n","    outputs = layers.Dense(units=1, activation=\"sigmoid\")(l)\n","\n","    model = keras.Model(inputs, outputs, name=\"3DCNN\")\n","    return model\n","\n","tf.random.set_seed(42)\n","model = model_image()\n","model.summary()"]},{"cell_type":"markdown","source":["## Compile and fit model"],"metadata":{"id":"iJX1C9Lw_ATg"},"id":"iJX1C9Lw_ATg"},{"cell_type":"code","execution_count":null,"id":"27d9f847","metadata":{"id":"27d9f847"},"outputs":[],"source":["model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"AUC\", tf.keras.metrics.Recall()])\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=os.path.join('PATH', '{epoch:03d}.h5'))\n","model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=2, epochs=70, callbacks=[checkpoint_cb])"]},{"cell_type":"markdown","source":["# **Test**"],"metadata":{"id":"f2BrweGsZab2"},"id":"f2BrweGsZab2"},{"cell_type":"markdown","source":["## Specify the path to the HFD5 file that had better sensitivity and AUC in the validation"],"metadata":{"id":"rJSVaopXA9cK"},"id":"rJSVaopXA9cK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1f574fc"},"outputs":[],"source":["model.load_weights(\"PATH\")"],"id":"a1f574fc"},{"cell_type":"markdown","source":["## Results"],"metadata":{"id":"g9s2lkrdD9Ep"},"id":"g9s2lkrdD9Ep"},{"cell_type":"code","source":["y_prediction = model.predict(x_test, batch_size=2, verbose=1)\n","y_prediction[y_prediction < 0.5] = 0\n","y_prediction[y_prediction >= 0.5] = 1\n","y_prediction = y_prediction.astype(\"int64\")\n","result = confusion_matrix(y_test, y_prediction)\n","sensitivity = recall_score(y_test, y_prediction)\n","specificity = recall_score(y_test, y_prediction, pos_label=0)\n","accuracy = accuracy_score(y_test, y_prediction)\n","auc = roc_auc_score(y_test, y_prediction)\n","print(result)\n","print(\"sensitivity: {:.3f}\".format(sensitivity))\n","print(\"specificity: {:.3f}\".format(specificity))\n","print(\"accuracy: {:.3f}\".format(accuracy))\n","print(\"AUC: {:.3f}\".format(auc))"],"metadata":{"id":"L9T8bGSohdDk"},"execution_count":null,"outputs":[],"id":"L9T8bGSohdDk"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[],"machine_shape":"hm","gpuClass":"premium"}},"nbformat":4,"nbformat_minor":5}